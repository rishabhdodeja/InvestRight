# -*- coding: utf-8 -*-
"""StartUp_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vbuebxp_MWdhvfWi9LmcswJF6rQXz8dE

# Download Crunchbase Datasets

*source: GitHub (notpeter/crunchbase-data)*

*release: 2015-08-27*
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from difflib import SequenceMatcher
import math

companies = pd.read_csv('https://raw.githubusercontent.com/notpeter/crunchbase-data/master/companies.csv')
investments = pd.read_csv('https://raw.githubusercontent.com/notpeter/crunchbase-data/master/investments.csv')
acquisitions = pd.read_csv('https://raw.githubusercontent.com/notpeter/crunchbase-data/master/acquisitions.csv')
rounds = pd.read_csv('https://raw.githubusercontent.com/notpeter/crunchbase-data/master/rounds.csv')
additions = pd.read_csv('https://raw.githubusercontent.com/notpeter/crunchbase-data/master/additions.csv')

"""https://www.kaggle.com/kbrookshier/crunchbase-startup-investments

#Data Transformation

***Required New Variables***


##Not-Age Variables

All except age variables - Total count: 21
"""

df = pd.DataFrame(data=companies[['permalink','name']].values, columns = ['permalink', 'name'])
df

#roundD - 1 if company did a round-D else 0
df['roundD'] = np.zeros(df.shape[0])

#roundC - 1 if company did a round-C else 0
df['roundC'] = np.zeros(df.shape[0])

#roundB - 1 if company did a round-B else 0
df['roundB'] = np.zeros(df.shape[0])

#roundA - 1 if company did a round-A else 0
df['roundA'] = np.zeros(df.shape[0])

#VentureCapital = 1 if company has a venture else 0
df['VentureCapital'] = np.zeros(df.shape[0])

#IsTech = 1 if company is a Tech company else 0
df['IsTech'] = np.empty(df.shape[0])
df['IsTech'] = np.nan
tech_keys = ['tech','analytics', 'software', 'elec', 'web','manufacturing','internet','auto','smart','e-','data','develop','product','design','social media','games','system', 'network','platform','app', 'robot','bio','science']

#target = 1 if company went into acquisition (or IPO) else 0
df['target'] = np.zeros(df.shape[0])

#roundD_raised_amount = total amount raised by company in D rounds
df['roundD_raised_amount'] = np.empty(df.shape[0])
df['roundD_raised_amount'][:] = np.nan

#roundC_raised_amount = amount raised by company in C rounds
df['roundC_raised_amount'] = np.empty(df.shape[0])
df['roundC_raised_amount'][:] = np.nan

#roundB_raised_amount = total amount raised by company in B rounds
df['roundB_raised_amount'] = np.empty(df.shape[0])
df['roundB_raised_amount'][:] = np.nan

#roundA_raised_amount = total amount raised by company in A rounds
df['roundA_raised_amount'] = np.empty(df.shape[0])
df['roundA_raised_amount'][:] = np.nan

#total_investments = total no. of investments made to the company
df['total_investments'] = np.empty(df.shape[0])
df['total_investments'][:] = np.nan

#investment_per_round = average fund raised per round 
df['investment_per_round'] = np.empty(df.shape[0])
df['investment_per_round'][:] = np.nan

#funding_total_usd = total amound raised by company in all rounds
df['funding_total_usd'] = np.empty(df.shape[0])
df['funding_total_usd'][:] = np.nan

#total_acquisitions = no. of times company went into acquisition (or IPO)
df['total_acquisitions'] = np.zeros(df.shape[0])

#competitors_count = no. of competitiors
df['competitors_count'] = np.empty(df.shape[0])
df['competitors_count'][:] = np.nan

#competitors_acquired = no. of competitors went into acquisition (or IPO)
df['competitors_acquired'] = np.empty(df.shape[0])
df['competitors_acquired'][:] = np.nan

#country_code = Country Code (if available)
df['country_code'] = np.empty(df.shape[0])
df['country_code'][:] = np.nan

#funding_rounds = No of funding rounds company went in
df['funding_rounds'] = np.empty(df.shape[0])
df['funding_rounds'][:] = np.nan

#investors_per_round = average no. of investors per round
df['investors_per_round'] = np.empty(df.shape[0])
df['investors_per_round'][:] = np.nan

#top500_investors = average no. of investors per round
df['top500_investors'] = np.empty(df.shape[0])
df['top500_investors'][:] = np.nan
top_investors = investments['investor_name'].value_counts()[:500].index.tolist()

for i in range(30800,31900):
  cp = df.loc[i,'permalink']
  print("Companies completed:", i, " ,out of", companies.shape[0])
  
  company_details = companies.loc[companies['permalink']==cp]
  investments_in_company = investments.loc[investments['company_permalink'] ==  cp] 
  company_acquisitions = acquisitions.loc[acquisitions['company_permalink'] == cp]

  #Company Details:
  
  company_cat = company_details.loc[i,'category_list']
  if (isinstance(company_cat,str)):
    ## isTech
    df.loc[i,'IsTech'] = 0
    for key in tech_keys:
      if key in company_cat.lower():
        df.loc[i,'IsTech'] = 1
        break
      
  
  ## funding_rounds
  df.loc[i,'funding_rounds'] = company_details.loc[i,'funding_rounds']

  try:
    ## investment_per_round
    df.loc[i,'investment_per_round'] = float(company_details.loc[i,'funding_total_usd'])/float(company_details.loc[i,'funding_rounds'])

    ## funding_total_usd
    df.loc[i,'funding_total_usd'] = company_details.loc[i,'funding_total_usd']
  except:
    df.loc[i,'investment_per_round'] = np.nan
    df.loc[i,'funding_total_usd'] = np.nan
  
  ## investor_per_round - will be replaced from data in Investments Details (if available)
  df.loc[i, 'investors_per_round'] = 2
  
  ## total_investments - will be replaced from data in Investments Details (if available)
  df.loc[i,'total_investments'] = float(company_details.loc[i,'funding_rounds'])*2

  ## country_code  
  df.loc[i,'country_code'] = company_details.loc[i,'country_code']


  #Investment Details:
  
  if investments_in_company.shape[0] != 0:

    if 'D' in investments_in_company['funding_round_code'].tolist():
      ## roundD
      df.loc[i,'roundD'] = 1
      amt_list = investments_in_company.loc[investments_in_company['funding_round_code']=='D']['raised_amount_usd']
      amt_list.dropna()
      ## roundD_raised_amound
      df.loc[i,'roundD_raised_amount'] = np.mean(amt_list)

    if 'C' in investments_in_company['funding_round_code'].tolist():
      ## roundC
      df.loc[i,'roundC'] = 1
      amt_list = investments_in_company.loc[investments_in_company['funding_round_code']=='C']['raised_amount_usd']
      amt_list.dropna()
      ## roundC_raised_amound
      df.loc[i,'roundC_raised_amount'] = np.mean(amt_list)
      
    if 'B' in investments_in_company['funding_round_code'].tolist():
      ## roundB
      df.loc[i,'roundB'] = 1
      amt_list = investments_in_company.loc[investments_in_company['funding_round_code']=='B']['raised_amount_usd']
      amt_list.dropna()
      ## roundB_raised_amound
      df.loc[i,'roundB_raised_amount'] = np.mean(amt_list)

    if 'A' in investments_in_company['funding_round_code'].tolist():
      ## roundA
      df.loc[i,'roundA'] = 1
      amt_list = investments_in_company.loc[investments_in_company['funding_round_code']=='A']['raised_amount_usd']
      amt_list.dropna()
      ## roundA_raised_amount
      df.loc[i,'roundA_raised_amount'] = np.mean(amt_list)

    ## VentureCapital
    if 'venture' in investments_in_company['funding_round_type'].tolist():
      df.loc[i,'VentureCapital'] = 1
    
    ## total_investments
    df.loc[i,'total_investments'] = investments_in_company.shape[0]

    ## investor_per_round
    df.loc[i, 'investors_per_round'] = investments_in_company.shape[0]/company_details.loc[i, 'funding_rounds']
    
    ## top500_investors
    df.loc[i,'top500_investors'] = 0
    for investor in investments_in_company['investor_name'].tolist():
        if investor in top_investors:
          df.loc[i,'top500_investors'] += 1
    
  #Acquisition Details:
  
  if company_acquisitions.shape[0] != 0:  
    ## target
    df.loc[i,'target'] = 1
    ## total_acquisitions
    df.loc[i,'total_acquisitions'] = company_acquisitions.shape[0]
  
  
  #Competition Details

  competitors = companies.loc[companies['permalink']!=cp]
  if (isinstance(company_cat,str)):
     df.loc[i,'competitors_count'] = 0
     df.loc[i,'competitors_acquired'] = 0
     for j in competitors.index:
      try:
        if SequenceMatcher(None,competitors.loc[j,'category_list'],company_cat).ratio()>0.7:
          ## competitors_count
          df.loc[i,'competitors_count'] += 1
          if competitors.loc[j,'permalink'] in acquisitions['company_permalink'].tolist():
            ## competitors_acquired
            df.loc[i,'competitors_acquired'] += 1
      except:
        continue

  df.to_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_7a.csv', index=False)

"""##Age Variables"""

class Date:
    def __init__(self, d, m, y):
        self.d = d
        self.m = m
        self.y = y
monthDays = [31, 28, 31, 30, 31, 30,
             31, 31, 30, 31, 30, 31]
def countLeapYears(d): 
    years = d.y

    if (d.m <= 2):
        years -= 1
    ans = int(years / 4)
    ans -= int(years / 100)
    ans += int(years / 400)
    return ans
def getDifference(dt1, dt2):
    n1 = dt1.y * 365 + dt1.d
    for i in range(0, dt1.m - 1):
        n1 += monthDays[i]
    n1 += countLeapYears(dt1)
 
    n2 = dt2.y * 365 + dt2.d
    for i in range(0, dt2.m - 1):
        n2 += monthDays[i]
    n2 += countLeapYears(dt2)

    return (n2 - n1)

## roundX_age -  Company's age when it did its round X 
df_4 = pd.DataFrame(data=investments.values)
roundA_age = pd.DataFrame(columns = ['permalink', 'name', 'age'])
roundB_age = pd.DataFrame(columns = ['permalink', 'name', 'age'])
roundC_age = pd.DataFrame(columns = ['permalink', 'name', 'age'])
roundD_age = pd.DataFrame(columns = ['permalink', 'name', 'age'])
df_4 = df_4[[0,1,15,16]]
for i in range(df_4.shape[0]):
  if df_4.iloc[i][15]=='A':
    start = df_4.iloc[i][1]
    j,k = (df_3.applymap(lambda x: str(x).startswith(start))).values.nonzero()
    start_date = df_3.iloc[j[0]][11]
    end_date = df_4.iloc[i][16]
    if type(start_date) == float or type(end_date) == float:
      continue
    st_dt = [int(it) for it in start_date.replace('-', ' ').split(' ')] 
    ed_dt = [int(it) for it in end_date.replace('-', ' ').split(' ')] 
    roundA_age = roundD_age.append({'permalink' : df_4.iloc[i][0], 'name' : df_4.iloc[i][1], 'age' : getDifference(Date(st_dt[2],st_dt[1],st_dt[0]),Date(ed_dt[2],ed_dt[1],ed_dt[0]))},  
                ignore_index = True)
  if df_4.iloc[i][15]=='B':
    start = df_4.iloc[i][1]
    j,k = (df_3.applymap(lambda x: str(x).startswith(start))).values.nonzero()
    start_date = df_3.iloc[j[0]][11]
    end_date = df_4.iloc[i][16]
    if type(start_date) == float or type(end_date) == float:
      continue
    st_dt = [int(it) for it in start_date.replace('-', ' ').split(' ')] 
    ed_dt = [int(it) for it in end_date.replace('-', ' ').split(' ')] 
    roundB_age = roundD_age.append({'permalink' : df_4.iloc[i][0], 'name' : df_4.iloc[i][1], 'age' : getDifference(Date(st_dt[2],st_dt[1],st_dt[0]),Date(ed_dt[2],ed_dt[1],ed_dt[0]))},  
                ignore_index = True)
  if df_4.iloc[i][15]=='C':
    start = df_4.iloc[i][1]
    j,k = (df_3.applymap(lambda x: str(x).startswith(start))).values.nonzero()
    start_date = df_3.iloc[j[0]][11]
    end_date = df_4.iloc[i][16]
    if type(start_date) == float or type(end_date) == float:
      continue
    st_dt = [int(it) for it in start_date.replace('-', ' ').split(' ')] 
    ed_dt = [int(it) for it in end_date.replace('-', ' ').split(' ')] 
    roundC_age = roundD_age.append({'permalink' : df_4.iloc[i][0], 'name' : df_4.iloc[i][1], 'age' : getDifference(Date(st_dt[2],st_dt[1],st_dt[0]),Date(ed_dt[2],ed_dt[1],ed_dt[0]))},  
                ignore_index = True)
  if df_4.iloc[i][15]=='D':
    start = df_4.iloc[i][1]
    j,k = (df_3.applymap(lambda x: str(x).startswith(start))).values.nonzero()
    start_date = df_3.iloc[j[0]][11]
    end_date = df_4.iloc[i][16]
    if type(start_date) == float or type(end_date) == float:
      continue
    st_dt = [int(it) for it in start_date.replace('-', ' ').split(' ')] 
    ed_dt = [int(it) for it in end_date.replace('-', ' ').split(' ')] 
    roundD_age = roundD_age.append({'permalink' : df_4.iloc[i][0], 'name' : df_4.iloc[i][1], 'age' : getDifference(Date(st_dt[2],st_dt[1],st_dt[0]),Date(ed_dt[2],ed_dt[1],ed_dt[0]))},  
                ignore_index = True)

## age_yrs
df_4 = pd.DataFrame(data=companies.values)
actual_age = pd.DataFrame(columns = ['permalink', 'name', 'age'])

df_4 = df_4[[0,1,5,11]]
for i in range(df_4.shape[0]):
  if df_4.iloc[i][5]=='operating':
    start_date = df_4.iloc[i][11]
    end_date = "2020-12-16"
    if type(start_date) == float or type(end_date) == float:
      continue
    start_date = str(start_date)
    st_dt = [int(it) for it in start_date.replace('-', ' ').split(' ')] 
    ed_dt = [int(it) for it in end_date.replace('-', ' ').split(' ')] 
    actual_age = actual_age.append({'permalink' : df_4.iloc[i][0], 'name' : df_4.iloc[i][1], 'age' : getDifference(Date(st_dt[2],st_dt[1],st_dt[0]),Date(ed_dt[2],ed_dt[1],ed_dt[0]))},  
                ignore_index = True)

"""#Data Cleaning

**Concat all rows for NotAge Variables**

*data transformation needed hours of processing thus data was split and distributed among team members to process parallely*
"""

df1 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_1.csv')[0:4400]
df2 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_2.csv')[4400:8800]
df3 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_3.csv')[8800:13200]
df4 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_4.csv')[13200:17600]
df5 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_5.csv')[22000:26400]
df6 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_5 (1).csv')[17600:22000]
df7 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_6.csv')[26400:30800]
df8a = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_7a.csv')[30800:31900]
df8b = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_7b.csv')[31900:33000]
df8c = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_7c.csv')[33000:34100]
df8d = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_7d.csv')[34100:35200]             
df9 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_8.csv')[35200:39600]            
df10 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/NotAge21_66k_9.csv')[39600:44000]            
df11 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/final - 1c.csv')[44000:]

df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8a,df8b,df8c,df8d,df9,df10,df11,])
df

"""**Add Age Variable Columns (left join by company name & permalink)**"""

df_age1 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/actual_age.csv')
df_age2 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/success_age.csv')
df_age3 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/roundA_age.csv')
df_age4 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/roundB_age.csv')
df_age5 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/roundC_age.csv')
df_age6 = pd.read_csv('/content/drive/MyDrive/StartUp_Project/roundD_age.csv')

print(df_age2['permalink'].unique().shape, df_age1['permalink'].shape)

df_age1.value_counts(subset=['name'])

df_age1.loc[df_age1['name']=='500px']

df = df.merge(df_age1, how='left', on = ['permalink','name'])
df = df.merge(df_age2, how='left', on = ['permalink','name'])
df = df.merge(df_age3, how='left', on = ['permalink','name'])
df = df.merge(df_age4, how='left', on = ['permalink','name'])
df = df.merge(df_age5, how='left', on = ['permalink','name'])
df = df.merge(df_age6, how='left', on = ['permalink','name'])

"""**Cleaning NaN Values**"""

df.isnull().sum()

#drop companies for which we dont have investments data
in_investments = list(investments['company_permalink'].unique())
for i in range(df.shape[0]):
  if df.loc[i,'permalink'] in in_investments:
    if df.loc[i, 'roundD'] == 0:
      df.loc[i,'roundD_raised_amount'] = 0
    if df.loc[i, 'roundC'] == 0:
      df.loc[i,'roundC_raised_amount'] = 0
    if df.loc[i, 'roundB'] == 0:
      df.loc[i,'roundB_raised_amount'] = 0
    if df.loc[i, 'roundA'] == 0:
      df.loc[i,'roundA_raised_amount'] = 0
  else:
    df = df.drop(index=i)
  print(i)

df.isnull().sum()

# take inverse of ages as new variables so that we can replace nan values with zeros and scale up to preserve significant digits
df['success_age_inverse'] = 10000/df['success_age']
df['actual_age_inverse'] = 10000/df['actual_age']
df['roundD_age_inverse'] = 10000/df['roundD_age']
df['roundC_age_inverse'] = 10000/df['roundC_age']
df['roundB_age_inverse'] = 10000/df['roundB_age']
df['roundA_age_inverse'] = 10000/df['roundA_age']

#fill nan values with 0
df[['roundA_age_inverse','roundB_age_inverse','roundC_age_inverse','roundD_age_inverse','success_age_inverse']] = df[['roundA_age_inverse','roundB_age_inverse','roundC_age_inverse','roundD_age_inverse','success_age_inverse']].fillna(0)
#drop original age columns
df = df.drop(columns = ['roundA_age','roundB_age','roundC_age','roundD_age','success_age','actual_age'])

## drop companies with no name
df = df.dropna(subset = ['name'])

# redefine IsTech to remove nan values
tech_keys = ['tech','analytics', 'software', 'elec', 'web','manufacturing','internet','auto','smart','e-','data','develop','product','design','social media','games','system', 'network','platform','app', 'robot','bio','science']
for i in df.index:
  for key in tech_keys:
    if key in df.loc[i,'name']:
      df.loc[i,'IsTech'] = 1
    else:
      df.loc[i,'IsTech'] = 0
    if (isinstance(companies.loc[i,'category_list'],str)):
      if key in companies.loc[i,'category_list']:
        df.loc[i,'IsTech'] = 1
      else:
        df.loc[i,'IsTech'] = 0
  print(i)

df

#adding 2 extra variables

## status = current status of company (operational not operational)
## last_funding_at = year of last funding
for i in df.index:
  df.loc[i,'last_funding_at'] = int(companies.loc[i,'last_funding_at'][0:4])
  df.loc[i,'status'] = companies.loc[i,'status']

df.isnull().sum()

## competitor = 0 if not found
df[['competitors_count','competitors_acquired']] = df[['competitors_count','competitors_acquired']].fillna(0)

## take roundUp integer for investors_per_round
df['investors_per_round'] = df['investors_per_round'].apply(np.ceil)

df.to_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_raw.csv')
df

df['actual_age_inverse'] = df['actual_age_inverse'].fillna(df['actual_age_inverse'].median())
df_clean = df.dropna()
df_clean

df_clean.isnull().sum()

df_clean.to_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_cleaned.csv')

"""# Data Visualization"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()
# %matplotlib inline

df= pd.read_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_cleaned.csv', index_col=0)
#df2= pd.read_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_raw.csv', index_col=0)
df.info()

#numerical columns
df_num= df.drop(['permalink', 'name', 'country_code', 'status'], axis = 1)
df_num = df_num.astype('int64')
df_num

list(df_num.columns)

df['status'].value_counts()[:].plot(kind='pie')

for i in df_num.columns:
  if (df_num[i].unique().shape[0]) <= 5:
    df_num[i].value_counts()[:].plot(kind='pie')
    plt.title(i)
    plt.show()
  else:
    plt.hist(df_num[i])
    plt.title(i)
    plt.show()

#correlation plot
print(df_num.corr())
sns.heatmap(df_num.corr())

"""# XG-Boost Classification"""

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from matplotlib import pyplot
import joblib

#XGB handles missing values very well, thus using raw data itself
df = pd.read_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_raw.csv', index_col=0)

X = df.drop(columns = ['success_age_inverse','total_acquisitions','target', 'name', 'permalink'])
Y = df.target

le = LabelEncoder()

#transform country_code
X['country_code']=X['country_code'].map(str)
le.fit(X['country_code'])
X['country_code'] = le.transform(X['country_code'])
joblib.dump(le, '/content/drive/MyDrive/StartUp_Project/country_code_label.joblib')

#transfor status
le.fit(X['status'])
X['status'] = le.transform(X['status'])
joblib.dump(le, '/content/drive/MyDrive/StartUp_Project/status_label.joblib')

X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=7)
# fit model on training data
model = XGBClassifier(max_depth=70,n_estimators=150,learning_rate= 0.05)

eval_set = [(X_train, y_train), (X_test, y_test)]

model.fit(X_train, y_train,  early_stopping_rounds=15,eval_metric=["error", "logloss"], eval_set=eval_set, verbose=True)

# make predictions for test data
y_pred = model.predict(X_test)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(y_test, predictions)
print("Test Accuracy: %.2f%%" % (accuracy * 100.0))

# retrieve performance metrics
results = model.evals_result()
epochs = len(results['validation_0']['error'])
x_axis = range(0, epochs)

# plot log loss
fig, ax = pyplot.subplots()
ax.plot(x_axis, results['validation_0']['logloss'], label='Train')
ax.plot(x_axis, results['validation_1']['logloss'], label='Test')
ax.legend()
pyplot.ylabel('Log Loss')
pyplot.xlabel('Epochs')
pyplot.title('XGBoost Log Loss')
pyplot.show()

# plot classification error
fig, ax = pyplot.subplots()
ax.plot(x_axis, results['validation_0']['error'], label='Train')
ax.plot(x_axis, results['validation_1']['error'], label='Test')
ax.legend()
pyplot.ylabel('Classification Error')
pyplot.xlabel('Epochs')
pyplot.title('XGBoost Classification Error')
pyplot.show()

from tabulate import tabulate
cm = confusion_matrix(y_pred = predictions,y_true = y_test[:], labels=[0,1])
rows = np.array([["Actual Failures"], ["Actual Successfull"]])
rows = np.concatenate((rows,cm), axis=1)
headers = ["No. of Samples", "Predicted Failure", "Predicted Successfull"]
table = tabulate(rows,headers, tablefmt="grid")
print(table)

"""**Training Scores**"""

y_pred = model.predict(X_train)
predictions = [round(value) for value in y_pred]
# evaluate predictions
accuracy = accuracy_score(y_train, predictions)
print("Train Accuracy: %.2f%%" % (accuracy * 100.0))

from tabulate import tabulate
cm = confusion_matrix(y_pred = predictions,y_true = y_train[:], labels=[0,1])
rows = np.array([["Actual Failures"], ["Actual Successfull"]])
rows = np.concatenate((rows,cm), axis=1)
headers = ["No. of Samples", "Predicted Failure", "Predicted Successfull"]
table = tabulate(rows,headers, tablefmt="grid")
print(table)

model.save_model('/content/drive/MyDrive/StartUp_Project/xgb_model.json')

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression

df = pd.read_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_cleaned.csv', index_col=0)
X = df.drop(columns = ['success_age_inverse','total_acquisitions','target', 'name', 'permalink'])
Y = df.target

le = joblib.load('/content/drive/MyDrive/StartUp_Project/country_code_label.joblib')
X['country_code'] = X['country_code'].map(str)
X['country_code'] = le.transform(X['country_code'])

le = joblib.load('/content/drive/MyDrive/StartUp_Project/status_label.joblib')
X['status'] = le.transform(X['status'])

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=13)

# define class weights
w = {0:1, 1:1}
# define model
lgr = LogisticRegression(random_state=13, class_weight=w)
# fit it
lgr.fit(X_train,y_train)
# test
y_pred = lgr.predict(X_test)
# performance
print(f'Test Accuracy Score: {accuracy_score(y_test,y_pred)}')

cm = confusion_matrix(y_pred = y_pred,y_true = y_test[:], labels=[0,1])
rows = np.array([["Actual Failures"], ["Actual Successfull"]])
rows = np.concatenate((rows,cm), axis=1)
headers = ["No. of Samples", "Predicted Failure", "Predicted Successfull"]
table = tabulate(rows,headers, tablefmt="grid")
print(table)

"""**Training Scores**"""

y_pred = lgr.predict(X_train)
# performance
print(f'Train Accuracy Score: {accuracy_score(y_train,y_pred)}')

cm = confusion_matrix(y_pred = y_pred,y_true = y_train[:], labels=[0,1])
rows = np.array([["Actual Failures"], ["Actual Successfull"]])
rows = np.concatenate((rows,cm), axis=1)
headers = ["No. of Samples", "Predicted Failure", "Predicted Successfull"]
table = tabulate(rows,headers, tablefmt="grid")
print(table)

joblib.dump(lgr, '/content/drive/MyDrive/StartUp_Project/lgr_model.joblib')

"""#Data Imputation

To get good results with MLP we attempt to regain lost datapoint due to null values by imputing missing values.

Datawig is a package that does this job us. Based on deep learning techniques it imputes missing values of columns by using correlations & training NNs with other columns

https://github.com/awslabs/datawig
"""

pip install datawig

import datawig
df_imputed = datawig.SimpleImputer.complete(df)

df_imputed.to_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_cleaned.csv')

"""# MLP"""

# Binary Classification with Keras Neural Network
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold

# load dataset
df = pd.read_csv('/content/drive/MyDrive/StartUp_Project/Stratup_AllVariables_cleaned.csv', index_col=0)
dataset = df.values

X = df.drop(columns = ['success_age_inverse','total_acquisitions','target', 'name', 'permalink'])
Y = df.target

# encode class values as integers
encoder = LabelEncoder()
encoder.fit(Y)
encoded_Y = encoder.transform(Y)

le = joblib.load('/content/drive/MyDrive/StartUp_Project/country_code_label.joblib')
X['country_code'] = X['country_code'].map(str)
X['country_code'] = le.transform(X['country_code'])

le = joblib.load('/content/drive/MyDrive/StartUp_Project/status_label.joblib')
X['status'] = le.transform(X['status'])

X_train, X_test, y_train, y_test = train_test_split(X, encoded_Y, test_size=0.2, random_state=13)

"""## BaseLine Model with 2 Layers"""

# baseline model
def create_baseline():
	# create model
	model = Sequential()
	model.add(Dense(32, input_dim=26, activation='relu'))
	model.add(Dense(1, activation='sigmoid'))
	# Compile model
	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
	return model

# evaluate model with dataset
estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=2)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator, X_train, y_train, cv=kfold)
print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

"""## Deep Model with 4 Layers"""

def create_larger():
  # create model
  model = Sequential()
  model.add(Dense(32, input_dim=26, activation='relu'))
  model.add(Dense(16, activation='relu'))
  model.add(Dense(8, activation='relu'))
  model.add(Dense(1, activation='sigmoid'))
  # Compile model
  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

# evaluate model with dataset
estimator = KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=2)
kfold = StratifiedKFold(n_splits=10, shuffle=True)
results = cross_val_score(estimator, X_train, y_train, cv=kfold)
#print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

print("Deep MLP: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))

"""## **Final Model:** We will be using *`XGBoost`* as our final model, as it performs substantially well compared to *`Logistic Regression`* & *`MLP`*"""